{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "Ans. \n",
    "Lasso Regression is a regression technique that combines ordinary least squares regression with L1 regularization. It differs from other regression techniques, such as linear regression or ridge regression, by adding a penalty term that encourages sparsity in the coefficient estimates. This means that Lasso Regression can shrink some coefficients to exactly zero, effectively performing feature selection.\n",
    "\n",
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "Ans The main advantage of using Lasso Regression in feature selection is its ability to automatically select the most relevant features by shrinking the coefficients of irrelevant features to zero. This helps in reducing the complexity of the model and improving interpretability.\n",
    " \n",
    " Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    " Ans The coefficients of a Lasso Regression model can be interpreted in the same way as coefficients in linear regression. They represent the change in the target variable for a one-unit change in the corresponding feature, while holding other features constant. However, due to the L1 regularization, some coefficients may be exactly zero, indicating that those features have been excluded from the model.\n",
    "\n",
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?\n",
    "Ans In Lasso Regression, the tuning parameter that can be adjusted is called lambda (Î»), also known as the regularization parameter or penalty term. Lambda controls the amount of regularization applied to the model. Higher values of lambda result in more aggressive shrinkage of coefficients, potentially leading to more features being excluded. On the other hand, lower values of lambda reduce the amount of regularization, allowing more features to have non-zero coefficients. The choice of lambda can significantly affect the model's performance, and it is often selected using techniques like cross-validation.\n",
    "\n",
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "Ans Lasso Regression can be used for non-linear regression problems by incorporating non-linear transformations of the input features. By applying non-linear transformations, such as polynomial features or interaction terms, the model can capture non-linear relationships between the features and the target variable. However, it's important to note that the L1 regularization in Lasso Regression still promotes sparsity, so the non-linear transformations should be chosen carefully to avoid overfitting.\n",
    "\n",
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "Ans. The main difference between Ridge Regression and Lasso Regression lies in the type of regularization they use. Ridge Regression uses L2 regularization, which adds a penalty term proportional to the square of the coefficients, while Lasso Regression uses L1 regularization, which adds a penalty term proportional to the absolute value of the coefficients. This difference leads to different behaviors in terms of feature selection. Ridge Regression can shrink coefficients towards zero but does not typically set them exactly to zero, whereas Lasso Regression can perform feature selection by setting some coefficients to exactly zero.\n",
    " \n",
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how? \n",
    "Ans Yes, Lasso Regression can handle multicollinearity in the input features. Multicollinearity refers to the presence of strong correlations between the predictor variables. Lasso Regression can automatically select one variable from a set of highly correlated variables and shrink the coefficients of the rest to zero. This effectively handles multicollinearity by excluding redundant features from the model.\n",
    "\n",
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "Ans The optimal value of the regularization parameter (lambda) in Lasso Regression is typically chosen using techniques like cross-validation. Cross-validation involves splitting the data into multiple subsets, training the model on different combinations of the subsets, and evaluating the model's performance. By comparing the performance across different values of lambda, such as mean squared error or cross-validated R-squared, one can select the lambda that gives the best balance between model complexity and performance. Additionally, techniques like grid search or algorithms like coordinate descent can be used to efficiently search for the optimal value of lambda."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
